import pandas as pd
import numpy as np
import glob
import os
import matplotlib.pyplot as plt
import seaborn as sns
from pathlib import Path
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score

# ==========================================
# 1. 設定・パスの定義
# ==========================================

MALWARE_ROOT_DIR = r"D:\CSV_Flow\CSV_Attacked" 

# 正常データのフォルダ（*.csvまで記述）
NORMAL_DIR = r"D:\CSV_Flow\CSV_Normal\*.csv"

# サンプリング率（メモリ不足防止のため）
# 正常は全件(1.0)、攻撃は0.5%(0.005)など調整してください
RATIO_NORMAL = 1.0
RATIO_MALWARE = 0.005

# 学習・評価に不要な列
DROP_COLUMNS = [
    'flow_id', 'src_ip', 'dst_ip', 'src_port', 'dst_port', 'timestamp', 'label'
]

# ==========================================
# 2. 関数定義
# ==========================================

def load_csv_with_label(filepath, label_name, ratio):
    """ 指定されたファイルを読み込み、ラベルを付与して軽量化する """
    try:
        df = pd.read_csv(filepath)
        
        # 不要列削除
        cols_to_drop = [c for c in DROP_COLUMNS if c in df.columns]
        df.drop(columns=cols_to_drop, inplace=True)
        
        # サンプリング（指定割合だけ抽出）
        if ratio < 1.0:
            df = df.sample(frac=ratio, random_state=42)
            
        # データ型変換（軽量化）
        float_cols = df.select_dtypes(include=['float64']).columns
        df[float_cols] = df[float_cols].astype('float32')
        
        # ラベル付与
        df['label'] = label_name
        
        return df
    except Exception as e:
        print(f"  Error: {os.path.basename(filepath)} -> {e}")
        return pd.DataFrame()

def load_malware_from_folders(root_path, ratio):
    """ フォルダ構造を走査してデータを読み込む """
    df_list = []
    root = Path(root_path)
    
    # ルート以下のすべてのサブフォルダを取得
    subfolders = [f for f in root.iterdir() if f.is_dir()]
    print(f"検索対象フォルダ: {[f.name for f in subfolders]}")
    
    for folder in subfolders:
        label_name = folder.name  # フォルダ名をラベルにする
        csv_files = list(folder.glob("*.csv"))
        
        if not csv_files:
            continue
            
        print(f"--- Loading {label_name} ({len(csv_files)} files) ---")
        
        for file in csv_files:
            df = load_csv_with_label(file, label_name, ratio)
            if not df.empty:
                df_list.append(df)
                
    if not df_list:
        return pd.DataFrame()
    return pd.concat(df_list, ignore_index=True)

def preprocess_data(df):
    """ 前処理（シャッフル、Xとyの分離、欠損値処理） """
    if df.empty: return None, None
    
    # シャッフル
    df = df.sample(frac=1, random_state=42).reset_index(drop=True)
    
    y = df['label']
    X = df.drop(columns=['label'])
    
    # 欠損値処理
    X = X.replace([np.inf, -np.inf], np.nan).fillna(0)
    
    return X, y

# ==========================================
# 3. メイン処理
# ==========================================

def main():
    print("=== 多値分類処理を開始（フォルダベース） ===")

    # A. データの読み込み
    print("\n[Step 1] ファイル読み込み")
    
    # 1. 正常データの読み込み
    print("--- Normal Data ---")
    normal_files = glob.glob(NORMAL_DIR)
    df_list_normal = []
    for f in normal_files:
        df = load_csv_with_label(f, "Normal", RATIO_NORMAL)
        df_list_normal.append(df)
        
    if df_list_normal:
        df_normal = pd.concat(df_list_normal, ignore_index=True)
    else:
        df_normal = pd.DataFrame()
        print("警告: 正常データが見つかりません")

    # 2. 攻撃データの読み込み (フォルダ構造から自動取得)
    print("--- Malware Data ---")
    df_malware = load_malware_from_folders(MALWARE_ROOT_DIR, RATIO_MALWARE)

    # 結合して1つのデータセットにする
    df_full = pd.concat([df_normal, df_malware], ignore_index=True)

    print("\n[データ内訳]")
    print(df_full['label'].value_counts())

    if len(df_full) == 0:
        print("[停止] データがありません。パスを確認してください。")
        return

    # B. 前処理
    print("\n[Step 2] 前処理 & データ分割")
    X, y = preprocess_data(df_full)

    # ★重要: ここで学習用とテスト用に分割する (層化抽出)
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.3, random_state=42, stratify=y
    )
    
    print(f"  -> 学習用: {len(X_train)}件")
    print(f"  -> テスト用: {len(X_test)}件")

    # C. 学習
    print("\n[Step 3] 学習 (Random Forest)")
    rf_model = RandomForestClassifier(
        n_estimators=100, 
        class_weight='balanced', # 不均衡データ対策
        random_state=42,
        n_jobs=-1
    )
    rf_model.fit(X_train, y_train)
    print("  -> 完了")

    # D. 評価
    print("\n[Step 4] 評価結果")
    y_pred = rf_model.predict(X_test)

    print(f"正解率 (Accuracy): {accuracy_score(y_test, y_pred):.4f}")
    
    print("\n--- 分類レポート ---")
    # zero_division=0: データがないクラスがあってもエラーにしない
    print(classification_report(y_test, y_pred, zero_division=0))
    
    # 混同行列（ヒートマップ）
    print("\n--- 混同行列の表示 ---")
    labels = sorted(y_test.unique())
    cm = confusion_matrix(y_test, y_pred, labels=labels)
    
    plt.figure(figsize=(12, 10))
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=labels, yticklabels=labels)
    plt.ylabel('Actual Label') # 正解
    plt.xlabel('Predicted Label') # 予測
    plt.title('Confusion Matrix (Multiclass)')
    plt.xticks(rotation=45)
    plt.tight_layout()
    plt.show()

    # E. 特徴量重要度
    print("\n[Step 5] 重要な特徴量 Top 5")
    importances = rf_model.feature_importances_
    indices = np.argsort(importances)[::-1]
    features = X_train.columns
    for i in range(min(5, len(features))):
        print(f"{i+1}. {features[indices[i]]}: {importances[indices[i]]:.4f}")

if __name__ == "__main__":
    main()